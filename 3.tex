\documentclass[stat333]{subfiles}

%% ========================================================
%% document

\begin{document}

    \chap{Markov Chains}

    \section{Markov Chains}

    \begin{definition}{Stochastic Process}{}
        Any collection of random variables (or random vectors) of the form $\left\lbrace X\left( t \right) \right\rbrace^{}_{t\in\mT}$ is called a \emph{stochastic process}.
    \end{definition}

    \np Given a stochastic process $\left\lbrace X\left( t \right) \right\rbrace^{}_{t\in\mT}$ The index set $\mT$ is often interpreted in the context of time. As such, usually $\mT\subseteq\R$ and we say $X\left( t \right)$ is the \emph{state} of the process at time $t\in\mT$.

    \begin{definition}{Continuous-time, Discrete-time}{Stochastic Process}
        Let $\left\lbrace X\left( t \right) \right\rbrace^{}_{t\in\mT}$ be a stochastic process. We say $\left\lbrace X \right\rbrace^{}_{t\in\mT}$ is 
        \begin{enumerate}
            \item \emph{continuous-time} if $\mT$ is a (union of) continuum of real numbers; and
            \item \emph{discrete-time} if $\mT$ is a countable subset of real numbers.\footnote{In general, we use $\N\cup\left\lbrace 0 \right\rbrace$ as the index set of discrete-time stochastic processes. In fact, we shall use this convention throughout this note, unless otherwise specified.}
        \end{enumerate}
    \end{definition}

    \begin{definition}{Discrete-time Markov Chain (DTMC)}{}
        We say a discrete-time stochastic process $\left\lbrace X_n \right\rbrace^{}_{n\in\N\cup\left\lbrace 0 \right\rbrace}$ is a \emph{discrete-time Markov chain} (\emph{DTMC}) if
        \begin{enumerate}
            \item each $X_n$ is discrete; and
            \item for every $n\in\N\cup\left\lbrace 0 \right\rbrace$ and $x_0,\ldots,x_{n+1}$ in the codomain of $X_0,\ldots,X_{n+1}$, respectively,
                \begin{equation*}
                    \PP\left( X_{n+1}=x_{n+1}|X_{n}=x_{n},\ldots,X_0=x_0 \right) = \PP\left( X_{n+1}=x_{n+1}|X_{n}=x_{n} \right).\eqno\text{\textit{Markov property}}
                \end{equation*}
        \end{enumerate}
    \end{definition}

    \np In other words, the Markov property states that the conditional distribution of a \textit{future} state $X_{n+1}$ given the \textit{past} states $X_0,\ldots,X_{n-1}$ and the \textit{present} state $X_n$ is independent of the past states. It is also worth noting that the Markov property ensures that, given any $k_1,\ldots,k_l\in\left\lbrace 1,\ldots,n-1 \right\rbrace$ with $k_1<\cdots<k_l$,
    \begin{equation*}
        \PP\left( X_{n+1}=x_{n+1}|X_{k_l}=x_{k_l},\ldots,X_{k_1}=x_{k_1} \right) = \PP\left( X_{n+1}=x_{n+1}|X_{k_l}=x_{k_l} \right).
    \end{equation*}

    \begin{definition}{Transition Probability Matrix}{}
        For any pair of states $i,j\in\N\cup\left\lbrace 0 \right\rbrace$, the \emph{transition probability} from state $i$ at time $n$ to state $j$ at time $n+1$ is given by
        \begin{equation*}
            \PP\left( X_{n+1}=j|X_n=i \right)
        \end{equation*}
        for all $n\in\N\cup\left\lbrace 0 \right\rbrace$. The \emph{transition probability matrix} from time $n$ to time $n+1$ is defined as 
        \begin{equation*}
            \begin{bmatrix}
                P_{n,0,0} & P_{n,0,1} & \cdots \\
                P_{n,1,0} & P_{n,1,1} & \cdots \\
            	\vdots & \vdots & \ddots \\
            \end{bmatrix}
        \end{equation*}
        for all $n\in\N\cup\left\lbrace 0 \right\rbrace$, where $P_{n,i,j}=\PP\left( X_{n+1}=j|X_n=i \right)$ for all $i,j\in\N\cup\left\lbrace 0 \right\rbrace$.
    \end{definition}

    \clearpage
    \np It is clear from the construction that, given any TPM $P$,
    \begin{enumerate}
        \item every entry of $P$ is nonnegative; and
        \item for any row of $P$, the sum of the entries is $1$.
    \end{enumerate}
    Any matrix that satisfies (a), (b) is called \emph{stochastic}.

    \begin{definition}{Stationary (Homogeneous)}{DTMC}
        Let $\left\lbrace X_n \right\rbrace^{}_{n\in\N\cup\left\lbrace 0 \right\rbrace}$ be a DTMC. We say $\left\lbrace X_n \right\rbrace^{}_{n\in\N\cup\left\lbrace 0 \right\rbrace}$ is \emph{stationary} (or \emph{homogeneous}) if the transition probability is independent of the time.\footnote{We shall only consider stationary DTMCs in this note.} That is, for all times $n,m\in\N\cup\left\lbrace 0 \right\rbrace$ and indices $i,j\in\N\cup\left\lbrace 0 \right\rbrace$,
        \begin{equation*}
            \PP\left( X_{n+1}=j|X_n=i \right) = \PP\left( X_{m+1}=j|X_n=i \right).
        \end{equation*}
    \end{definition}


    \ex On a given day the weather is clear, overcast, or rainy. 
    If the weather is clear today, then it would be clear, overcast, or rainy tomorrow with respective probabilities $0.6,0.3,0.1$. 
    If the weather is overcast today, then it would be clear, overcast, or rainy tomorrow with respective probabilities $0.2,0.5,0.3$. 
    If the weather is rainy today, then it would be clear, overcast, or rainy tomorrow with respective probabilities $0.4,0.2,0,4$. 
    Construct the underlying DTMC and determine its TPM.

    \begin{subproof}[Answer]
        Note that the weather tomorrow only depends on the weather today, implying that the Markov property holds. Hence, letting
        \begin{equation*}
            X_n = 
            \begin{cases} 
                0 & \text{if the weather on $n$th day is clear}\\
                1 & \text{if the weather on $n$th day is overcast}\\
                2 & \text{if the weather on $n$th day is rainy}
            \end{cases},
        \end{equation*}
        $\left( X_{n} \right)^{}_{n\in\N\cup\left\lbrace 0 \right\rbrace}$ is a $3$-state DTMC. Moreover, the TPM is given by
        \begin{equation*}
            \begin{bmatrix}
            	0.6 & 0.3 & 0.1 \\
            	0.2 & 0.5 & 0.3 \\
            	0.4 & 0.2 & 0.4 \\
            \end{bmatrix}. \eqqedsym
        \end{equation*}
    \end{subproof}

    \begin{definition}{$n$-step Transition Probability}{}
        Suppose that we have a DTMC $\left\lbrace X_n \right\rbrace^{}_{n\in\N\cup\left\lbrace 0 \right\rbrace}$. For every states $i,j\in\N\cup\left\lbrace 0 \right\rbrace$ and $n\in\N\cup\left\lbrace 0 \right\rbrace$, we define the \emph{$n$-step transition probability}, commonly denoted as $P^{\left( n \right)}_{i,j}$, as
        \begin{equation*}
            P^{\left( n \right)}_{i,j} = \PP\left( X_{m+n}=j|X_m=i \right),
        \end{equation*}
        where $m\in\N\cup\left\lbrace 0 \right\rbrace$.\footnote{The definition is independent of $m$ since we assumed our DTMC to be stationary. In other words, we may define $P^{\left( n \right)}_{i,j}=\PP\left( X_n=j|X_0=i \right)$.} We call
        \begin{equation*}
            P^{\left( n \right)} = \left[ P^{\left( n \right)}_{i,j} \right]_{i,j\in\N\cup\left\lbrace 0 \right\rbrace}
        \end{equation*}
        the \emph{$n$-step transition probability matrix} (\emph{$n$-step TPM}).
    \end{definition}

    \clearpage
    \np Consider a DTMC $\left\lbrace X_n \right\rbrace^{}_{n\in\N\cup\left\lbrace 0 \right\rbrace}$, its TPM $P$, and $n$-step TPMs $P^{\left( 0 \right)}, \ldots$.
    \begin{enumerate}
        \item From the construction, it is evident that
            \begin{equation*}
                P^{\left( 0 \right)}_{i,j}=\delta_{ij}
            \end{equation*}
            for every states $i,j$, where $\delta$ is the Kronecker delta. It follows that $P^{\left( 0 \right)}$ is the identity matrix.
        \item $P^{\left( 1 \right)}=P$.
    \end{enumerate}
    
    \np[Chapman-Kolmogorov Equations]For any $n\in\N$, we have
    \begin{equation}
        P^{\left( n \right)}_{i,j} = \sum^{\infty}_{k=0}P^{\left( n-1 \right)}_{i,k}P_{k,j}.
    \end{equation}

    \begin{subproof}
        Observe that    
        \begin{flalign*}
            && P^{\left( n \right)}_{i,j} & = \PP\left( X_n=j|X_0=i \right) && \\ 
            && & = \sum^{\infty}_{k=0}\PP\left( X_n=j|X_{n-1}=k,x_0=i \right)\PP\left( X_{n-1}=k|X_0=i \right) && \\
            && & = \sum^{\infty}_{k=0}P^{\left( n-1 \right)}_{i,k}\PP\left( X_n=j|X_{n-1}=k,X_0=i \right) && \\
            && & = \sum^{\infty}_{k=0}P^{\left( n-1 \right)}_{i,k}\PP\left( X_n=j|X_{n-1}=k \right) && \text{by Markov property}\\
            && & = \sum^{\infty}_{k=0}P^{\left( n-1 \right)}_{i,k}P_{k,j}, 
        \end{flalign*} 
        as required.
    \end{subproof}
    
    \noindent This in particular implies that,
    \begin{equation}
        P^{\left( n \right)} = P^{\left( n-1 \right)}P
    \end{equation}
    for every $n\in\N$, and as a corollary,
    \begin{eqbox}[Chapman-Komogorov Equations for a DTMC]
        \begin{equation}
            P^{\left( n \right)}_{i,j} = \sum^{\infty}_{k=0}P^{\left( m \right)}_{i,k}P^{\left( n-m \right)}_{k,j}
        \end{equation}
    \end{eqbox} 
    for every $i,j\in\N\cup\left\lbrace 0 \right\rbrace$ and $n\in\N, m\in\left\lbrace 0,\ldots,n \right\rbrace$. In matrix form, this translates to
    \begin{eqbox}[Chapman-Komogorov Equations in Matrix Form]
        \begin{equation}
            P^{\left( n \right)} = P^{\left( m \right)}P^{\left( n-m \right)}.
        \end{equation}
    \end{eqbox} 

    \np Consider the row vector
    \begin{equation*}
        \alpha_n = \begin{bmatrix} \alpha_{n,0} & \alpha_{n,1} & \cdots  \end{bmatrix}
    \end{equation*}
    for every $n\in\N\cup\left\lbrace 0 \right\rbrace$, where
    \begin{equation*}
        \alpha_{n,k} = \PP\left( X_n=k \right)
    \end{equation*}
    for every $k\in\N$. In other words, $\alpha_n$ represents the marginal pmf of $X_n$, and as a consequence,
    \begin{equation*}
        \sum^{\infty}_{k=0}\alpha_{n,k} = 1.
    \end{equation*}
    In case $n=0$, $\alpha_0$ is referred to as the \emph{initial conditions} (or \emph{initial probability row vector}) of the DTMC. Now let us see how we can calculate $\alpha_n$. For every $n\in\N, m\in\left\lbrace 0,\ldots,n \right\rbrace$, note that
    \begin{flalign*}
        && \alpha_{n,k} & = \PP\left( X_n=k \right) && \\ 
        && & = \sum^{\infty}_{i=0}\PP\left( X_n=k|X_m=i \right)\PP\left( X_m=i \right) && \\
        && & = \sum^{\infty}_{i=0}\alpha_{m,i}\PP\left( X_{n-m}=k|X_0=i \right) && \text{since the DTMC is stationary} \\
        && & = \sum^{\infty}_{i=0}\alpha_{m,i}P_{i,k}^{\left( n-m \right)}.
    \end{flalign*} 
    In matrix form,
    \begin{equation*}
        \alpha_n = \alpha_mP^{\left( n-m \right)} = \alpha_mP^{n-m},
    \end{equation*}
    or
    \begin{eqbox}[Marginal PDF of $X_n$]
        \begin{equation}
            \alpha_n = \alpha_0P^n.
        \end{equation}
    \end{eqbox} 

    \np Having knowledge of the initial conditions and the one-step transition probabilities, one can calculate various probabilites of possible interest, such as
    \begin{flalign*}
        && \PP\left( X_n=x_n, \ldots, X_0=x_0 \right)& = \PP\left( X_0=x_0 \right)\PP\left( X_1=x_1|X_0=x_0 \right)\cdots\PP\left( X_n=x_n|X_{n-1}=x_{n-1},\ldots,X_0=x_0 \right) && \\ 
        && & = \PP\left( X_0=x_0 \right)\PP\left( X_1=x_1|X_0=x_0 \right)\cdots\PP\left( X_n=x_n|X_{n-1}=x_{n-1} \right) && \\
        && & = \alpha_{0,x_0}P_{x_0,x_1}\cdots P_{x_{n-1},x_n}. 
    \end{flalign*} 
    Similarly,
    \begin{flalign*}
        && & \PP\left( X_{n+m}=x_{n+m},\ldots,X_{n+1}=x_{n+1}|X_n=x_n \right) && \\
        && & = \frac{\PP\left( X_{n+m}=x_{n+m},\ldots,X_n=x_n \right)}{\PP\left( X_n=x_n \right)} && \\ 
        && & = \frac{\PP\left( X_n=x_n \right)\PP\left( X_{n+1}=x_{n+1}|X_n=x_n \right)\cdots\PP\left( X_{n+m}=x_{n+m}|X_{n+m-1}=x_{n+m-1},\ldots,X_n=x_n \right)}{\PP\left( X_n=x_n \right)} && \\
        && & = P_{x_n,x_{n+1}}\cdots P_{x_{n+m-1},x_{n+m}}.
    \end{flalign*} 
    The key observation is that the DTMC is \textit{completely characterized} by its one-step TPM $P$ and the initial conditions $\alpha_0$.
    
    \ex A particle moves along the states $0,1,2$ according to a DTMC whose TPM $P$ is given by
    \begin{equation*}
        P = 
        \begin{bmatrix}
        	0.7 & 0.2 & 0.1 \\
        	0 & 0.6 & 0.4 \\
        	0.5 & 0 & 0.5 \\
        \end{bmatrix}.
    \end{equation*}
    Let $X_n$ denote the position of the particle after the $n$th move (i.e. the DTMC is $\left\lbrace X_n \right\rbrace^{}_{n\in\N\cup\left\lbrace 0 \right\rbrace}$). Suppose that the particle is equally likely to start in any of the three positions.
    \begin{enumerate}
        \item Calculate $\PP\left( X_3=1|X_0=0 \right)$.

            \begin{subproof}[Answer]
                We desire to find $P_{0,1}^{\left( 3 \right)}$. To get this, we proceed to calculate $P^{\left( 3 \right)}$, the $3$-step transition TPM, which satisfies
                \begin{equation*}
                    P^{\left( 3 \right)} = P^3
                \end{equation*}
                where $P$ is the TPM. First of all,
                \begin{equation*}
                    P^2 = 
                    \begin{bmatrix}
                    	0.54 & 0.26 & 0.2 \\
                    	0.2 & 0.36 & 0.44 \\
                    	0.6 & 0.1 & 0.3 \\
                    \end{bmatrix}
                \end{equation*}
                and
                \begin{equation*}
                    P^3 = 
                    \begin{bmatrix}
                    	0.478 & 0.264 & 0.258 \\
                    	0.36 & 0.256 & 0.384 \\
                    	0.57 & 0.18 & 0.25 \\
                    \end{bmatrix}
                \end{equation*}
                by direct calculations. Thus,
                \begin{equation*}
                    P_{0,1}^{\left( 3 \right)} = P_{0,1}^3 = 0.264. \eqqedsym
                \end{equation*}
            \end{subproof}

        \item Calculate $\PP\left( X_4=2 \right)$.

            \begin{subproof}[Answer]
                We desire to find
                \begin{equation*}
                    \alpha_{4,2} = \PP\left( X_4=2 \right).
                \end{equation*}
                To do so, let us calculate $\alpha_4$, which satisfies
                \begin{equation*}
                    \alpha_4 = \alpha_0P^4.
                \end{equation*}
                By a direct calculation,
                \begin{equation*}
                    P^4 = 
                    \begin{bmatrix}
                    	\frac{1159}{2500} & \frac{127}{500} & \frac{353}{1250} \\
                    	\frac{111}{250} & \frac{141}{625} & \frac{413}{1250} \\
                    	\frac{131}{250} & \frac{111}{500} & \frac{127}{500} \\
                    \end{bmatrix},
                \end{equation*}
                so
                \begin{equation*}
                    \alpha_4 = \alpha_0P^4 = \begin{bmatrix} \frac{1}{3} & \frac{1}{3} & \frac{1}{3} \end{bmatrix}
                    \begin{bmatrix}
                    	\frac{1159}{2500} & \frac{127}{500} & \frac{353}{1250} \\
                    	\frac{111}{250} & \frac{141}{625} & \frac{413}{1250} \\
                    	\frac{131}{250} & \frac{111}{500} & \frac{127}{500} \\
                    \end{bmatrix}
                    =
                    \begin{bmatrix} \frac{1193}{2500} & \frac{877}{3750} & \frac{2167}{7500} \end{bmatrix}.
                \end{equation*}
                Thus
                \begin{equation*}
                    \alpha_{4,2} = \frac{2167}{7500}. \eqqedsym
                \end{equation*}
            \end{subproof}

        \item Calculate $\PP\left( X_6=0, X_4=2 \right)$.

            \begin{subproof}[Answer]
                We have
                \begin{equation*}
                    \PP\left( X_6=0, X_4=2 \right) = \PP\left( X_4=2 \right)\PP\left( X_6=0|X_4=2 \right) = \alpha_{4,2}P^{\left( 2 \right)}_{2,0} = 0.17336. \eqqedsym
                \end{equation*}
            \end{subproof}

        \item Calculate $\PP\left( X_9=0, X_7=2|X_5=1, X_2=0 \right)$.

            \begin{subproof}[Answer]
                We have
                \begin{flalign*}
                    && & \PP\left( X_9=0, X_7=2|X_5=1, X_2=0 \right) && \\
                    && & = \PP\left( X_7=2|X_5=1,X_4=0 \right)\PP\left( X_9=0|X_7=2,X_5=1,X_2=0 \right)  && \\
                    && & = \PP\left( X_7=2|X_5=1 \right)\PP\left( X_9=0|X_7=2 \right) = P^{\left( 2 \right)}_{1,2}P^{\left( 2 \right)}_{2,0} = 0.264.&&\fqqedsym
                \end{flalign*} 
            \end{subproof}
    \end{enumerate}

    \section{Accessibility and Communication}
    
    \begin{definition}{Accessble}{State}
        Let $i,j$ be states of a DTMC with $n$-step TPMs $P^{\left( n \right)}$.
        \begin{enumerate}
            \item We say $j$ is \emph{accessible} from state $i$, denoted as $i\to j$, if there exists $n\in\N\cup\left\lbrace 0 \right\rbrace$ such that $P^{\left( n \right)}_{i,j}>0$.
            \item We say $i,j$ \emph{communicate}, denoted as $i\lra j$ if $i\to j, j\to i$.
        \end{enumerate}
    \end{definition}

    \np In terms of accessibility, note that the magnitude of the components of $P$ do not matter. All that matters is which are positive and which are $0$. In particular, if state $j$ is not accessible from state $i$, then $P^{\left( n \right)}_{i,j} = 0$ for every $n\in\N\cup\left\lbrace 0 \right\rbrace$, and
    \begin{flalign*}
        && \PP\left( \exists m\in\N\cup\left\lbrace 0 \right\rbrace\left[ X_m = j \right]|X_0=i \right) & = \PP\left( \bigcup_{n\in\N\cup\left\lbrace 0 \right\rbrace}\left\lbrace X_n=j \right\rbrace|X_0=i \right) && \\ 
        && & \leq \sum^{\infty}_{n=0}\PP\left( X_n=j|X_0=i \right) = \sum^{\infty}_{n=0}P^{\left( n \right)}_{i,j} = 0.
    \end{flalign*} 
    In other words, if $j$ is not accessible from $i$, then the probability that the DTMC ever visits state $j$ given $X_0=i$ is $0$.

    \np Communication is an \textit{equivalence relation}. That is, given any states $i,j,k$, 
    \begin{enumerate}
        \item $i\lra i$;\hfill\textit{reflexivity}
        \item $i\lra j$ implies $j\lra i$; and\hfill\textit{symmetry}
        \item $i\lra j, j\lra k$ implies $i\lra k$.\hfill\textit{transitivity}
    \end{enumerate}

    \begin{subproof}
        (a), (b) are clear. To show transitivity, we know that there are $n,m\in\N\cup\left\lbrace 0 \right\rbrace$ such that $P^{\left( n \right)}_{i,j},P^{\left( m \right)}_{j,k}>0$. Then by the Chapman-Kolmogorov equations,
        \begin{equation*}
            P_{i,k}^{\left( n+m \right)} = \sum^{\infty}_{l=0}P_{i,l}^{\left( n \right)}P_{l,k}^{\left( m \right)}\geq P_{i,j}^{\left( n \right)}P_{j,k}^{\left( m \right)}>0.
        \end{equation*}
        Hence $i\to k$. Using the same logic, $k\to i$. Thus $i\lra k$.
    \end{subproof}

    \noindent The fact that communication forms an equivalence relation allows us to \textit{partition} all the states of a DTMC into equivalence classes, called \emph{communication classes}, so that within each class, all states communicate. For any states $i,j$ belong to distinct classes, \textit{at most} one of $i\to j, j\to i$ holds.

    \begin{definition}{Irreducible, Reducible}{DTMC}
        A DTMC is called
        \begin{enumerate}
            \item \emph{irreducible} if it has only one communcation class; and
            \item \emph{reducible} if not irreducible.
        \end{enumerate}
    \end{definition}

    \ex Suppose that the TPM $P$ of a DTMC is
    \begin{equation*}
        P = \left[ P_{i,j} \right]^{2}_{i,j=0}
        \begin{bmatrix}
        	0.7 & 0.2 & 0.1 \\
        	0 & 0.6 & 0.4 \\
        	0.5 & 0 & 0.5 \\
        \end{bmatrix}.
    \end{equation*}
    Find the communication classes of the DTMC.

    \begin{subproof}[Answer]
        We are going to draw a \textit{state transition diagram}.
        \begin{center}
            \begin{tikzpicture}[main/.style={draw,circle},node distance={2cm}]
                \node[main](0){$0$};
                \node[main](1)[right of=0]{$1$};
                \node[main](2)[below of=0]{$2$};
                \draw[->](0) to [out=90,in=180,looseness=3] (0);
                \draw[->](0) -- (1);
                \draw[->](0) to [out=270,in=180,looseness=0.5] (2);
                \draw[->](1) to [out=90,in=0,looseness=3] (1);
                \draw[->](1) -- (2);
                \draw[->](2) to [out=270,in=0,looseness=3] (2);
                \draw[->](2) -- (0);
            \end{tikzpicture}
        \end{center}
        Thus $\left\lbrace 0,1,2 \right\rbrace$ is the only communication class of the DTMC; in other words, the DTMC is irreducible.
    \end{subproof}

    \ex Consider a DTMC with TPM
    \begin{equation*}
        P =
        \begin{bmatrix}
        	0 & 1 & 0 & 0 \\
        	0 & 0 & 1 & 0 \\
        	0 & 0 & 0 & 1 \\
        	\frac{1}{2} & 0 & \frac{1}{2} & 0 \\
        \end{bmatrix}.
    \end{equation*}
    Find the communication classes of this DTMC.

    \begin{subproof}[Answer]
        By drawing a state transition diagram, it is clear that the DTMC is irreducible.
    \end{subproof}

    \ex Consider a DTMC with TPM
    \begin{equation*}
        P =
        \begin{bmatrix}
        	\frac{1}{3} & \frac{2}{3} & 0 & 0 \\
        	\frac{1}{2} & \frac{1}{4} & \frac{1}{8} & \frac{1}{8} \\
        	0 & 0 & 1 & 0 \\
        	\frac{3}{4} & \frac{1}{4} & 0 & 0 \\
        \end{bmatrix}.
    \end{equation*}
    Find the communication classes of this DTMC.

    \begin{subproof}[Answer]
        Observe that the state transition diagram is
        \begin{center}
            \begin{tikzpicture}[main/.style={draw,circle},node distance={2cm}]
                \node[main](0){$0$};
                \node[main](1)[above right of=0]{$1$};
                \node[main](2)[below right of=1]{$2$};
                \node[main](3)[below right of=0]{$3$};
                \draw[->](0) to [out=90,in=180,looseness=3] (0);
                \draw[->](0) -- (1);
                \draw[->](1) to [out=90,in=0,looseness=3] (1);
                \draw[->](1) -- (0);
                \draw[->](1) -- (2);
                \draw[->](1) -- (3);
                \draw[->](2) to [out=270,in=0,looseness=3] (2);
                \draw[->](3) -- (0);
                \draw[->](3) -- (1);
            \end{tikzpicture}
        \end{center}
        Thus $\left\lbrace 0,1,3 \right\rbrace, \left\lbrace 2 \right\rbrace$ are the communication classes of the DTMC.
    \end{subproof}

    \clearpage
    \section{Periodicity}
    
    \begin{definition}{Period}{of a State of a DTMC}
        Let $P$ be the TPM of a DTMC. Given a state $i$ of the DTMC, we define the \emph{period} of $i$, denoted as $d\left( i \right)$, by
        \begin{equation*}
            d\left( i \right) = 
            \begin{cases} 
                \gcd\left\lbrace n\in\N: P^{\left( n \right)}_{i,i}>0 \right\rbrace & \text{if there is $n\in\N$ such that $P^{\left( n \right)}_{i,i}>0$} \\
                \infty & \text{otherwise}
            \end{cases}.
        \end{equation*}
        If $d\left( i \right)=1$, then we say $i$ is \emph{aperiodic}, and if every state of a DTMC is aperiodic, then we call the DTMC \emph{aperiodic}.
    \end{definition}

    \ex Consider a DTMC with TPM
    \begin{equation*}
        P =
        \begin{bmatrix}
        	\frac{1}{3} & 0 & 0 & \frac{2}{3} \\
        	\frac{1}{2} & \frac{1}{4} & \frac{1}{8} & \frac{1}{8} \\
        	0 & 0 & 1 & 0 \\
        	\frac{3}{4} & 0 & 0 & \frac{1}{4} \\
        \end{bmatrix}.
    \end{equation*}
    Determine the communication classes of this DTMC and the period of each state.

    \begin{subproof}[Answer]
        Note that the state transition diagram of the DTMC is the following.
        \begin{center}
            \begin{tikzpicture}[main/.style={draw,circle},node distance={2cm}]
                \node[main](0){$0$};
                \node[main](1)[above right of=0]{$1$};
                \node[main](2)[below right of=1]{$2$};
                \node[main](3)[below right of=0]{$3$};
                \draw[->](0) to [out=90,in=180,looseness=3] (0);
                \draw[->](0) -- (3);
                \draw[->](1) to [out=90,in=0,looseness=3] (1);
                \draw[->](1) -- (0);
                \draw[->](1) -- (2);
                \draw[->](1) -- (3);
                \draw[->](2) to [out=270,in=0,looseness=3] (2);
                \draw[->](3) -- (0);
                \draw[->](3) to [out=270,in=0,looseness=3] (3);
            \end{tikzpicture}
        \end{center}
        Hence the communication classes are $\left\lbrace 0,3 \right\rbrace, \left\lbrace 1 \right\rbrace, \left\lbrace 2 \right\rbrace$. Moreover, we note that
        \begin{equation*}
            d\left( 0 \right) = d\left( 1 \right) = d\left( 2 \right) = d\left( 3 \right) = 1,
        \end{equation*}
        since
        \begin{equation*}
            P{\left( 1 \right)}_{i,i} = P_{i,i} > 0
        \end{equation*}
        for all $i\in\left\lbrace 0,1,2,3 \right\rbrace$. Thus we conclude that the DTMC is aperiodic.
    \end{subproof}

    \ex Consider a DTMC with TPM
    \begin{equation*}
        P =
        \begin{bmatrix}
        	0 & 1 & 0 & 0 \\
        	0 & 0 & 1 & 0 \\
        	0 & 0 & 0 & 1 \\
        	\frac{1}{2} & 0 & \frac{1}{2} & 0 \\
        \end{bmatrix}.
    \end{equation*}
    Determine the period of each state.

    \begin{subproof}[Answer]
        The state transition diagram of the DTMC is the following.
        \begin{center}
            \begin{tikzpicture}[main/.style={draw,circle},node distance={2cm}]
                \node[main](0){$0$};
                \node[main](1)[above right of=0]{$1$};
                \node[main](2)[below right of=1]{$2$};
                \node[main](3)[below right of=0]{$3$};
                \draw[->](0) -- (1);
                \draw[->](1) -- (2);
                \draw[->](2) -- (3);
                \draw[->](3) -- (0);
                \draw[->](3) -- (2);
            \end{tikzpicture}
        \end{center}
        Note that it is clear from the diagram that
        \begin{equation*}
            P^{\left( n \right)}_{i,i}>0
        \end{equation*}
        only if $n$ is even for every $i\in\left\lbrace 0,1,2,3 \right\rbrace$. This means $d\left( i \right)\in\left\lbrace 2,4 \right\rbrace$ for all $i\in\left\lbrace 0,1,2,3 \right\rbrace$. For each $i\in\left\lbrace 0,1 \right\rbrace$, note that $P^{\left( 4 \right)}_{i,i}, P^{\left( 6 \right)}_{i,i} > 0$, so 
        \begin{equation*}
            d\left( 0 \right)=d\left( 1 \right)=2.
        \end{equation*}
        Moreover, for each $i\in\left\lbrace 2,3 \right\rbrace$, note that $P^{\left( 2 \right)}_{i,i}, P^{\left( 4 \right)}_{i,i}>0$, so
        \begin{equation*}
            d\left( 2 \right)=d\left( 3 \right)=2.
        \end{equation*}
        Thus $d\left( i \right)=2$ for all $i\in\left\lbrace 0,1,2,3 \right\rbrace$.
    \end{subproof}

    \ex Consider the DTMC with TPM
    \begin{equation*}
        P =
        \begin{bmatrix}
        	\frac{1}{2} & \frac{1}{2} & 0 & 0 \\
        	\frac{2}{3} & \frac{1}{3} & 0 & 0 \\
        	0 & 0 & 0 & 1 \\
        	0 & 0 & 1 & 0 \\
        \end{bmatrix}.
    \end{equation*}
    Find the communication classes of  this DTMC and determine the period of each state.

    \begin{subproof}[Answer]
        It is clear from the definition of $P$ that
        \begin{equation*}
            0\lra 1, 2\lra 3.
        \end{equation*}
        Also note that $P$ is a block diagonal matrix of the form
        \begin{equation*}
            P =
            \begin{bmatrix}
            	A & 0 \\
            	0 & B \\
            \end{bmatrix}
        \end{equation*}
        for some $A,B\in M_{2\times 2}(\R)$. This means
        \begin{equation*}
            P^n = 
            \begin{bmatrix} 
                A^n & 0 \\
                0 & B^n
            \end{bmatrix}
        \end{equation*}
        for every $n\in\N\cup\left\lbrace 0 \right\rbrace$, so the communication classes are $\left\lbrace 0,1 \right\rbrace, \left\lbrace 2,3 \right\rbrace$. Moreover, $P_{0,0}, P_{1,1}>0$, so $d\left( 0 \right)=d\left( 1 \right)=1$. Lastly, 
        \begin{equation*}
            B^n = 
            \begin{cases} 
                I_2 & \text{if $n$ is even}\\
                B & \text{if $n$ is odd}
            \end{cases},
        \end{equation*}
        so $d\left( 2 \right)=d\left( 3 \right)=2$.
    \end{subproof}

    \begin{prop}{Communication Preserves Periodicity}
        If $i,j$ are states of a DTMC that communicates, then $d\left( i \right)=d\left( j \right)$.
    \end{prop}

    \begin{proof}
        Since the result is clearly true when $i=j$, assume $i\neq j$. Since $i\lra j$, we know by definition that
        \begin{equation*}
            P^{\left( m \right)}_{j,i}, P^{\left( n \right)}_{i,j}>0
        \end{equation*}
        for some $n,m\in\N$. Moreover, since $i\lra j$ means $i\to j$ and $j\to i$, there exists $s\in\N$ such that
        \begin{equation*}
            P_{j,j}^{\left( s \right)}>0.
        \end{equation*}
        Note that 
        \begin{enumerate}
            \item $P_{i,i}^{\left( n+m \right)} \geq P^{\left( n \right)}_{i,j}P^{\left( m \right)}_{j,i} > 0$; and
            \item $P_{i,i}^{\left( n+m+s \right)} \geq P^{\left( n \right)}_{i,j}P^{\left( s \right)}_{j,j}P^{\left( m \right)}_{j,i} > 0$.
        \end{enumerate}
        (a), (b) implies that
        \begin{equation*}
            d\left( i \right)|s,
        \end{equation*}
        and in particular that
        \begin{equation*}
            d\left( i \right)|d\left( j \right).
        \end{equation*}
        By using the same argument, we also conclude that
        \begin{equation*}
            d\left( j \right)|d\left( i \right).
        \end{equation*}
        Thus $d\left( j \right)=d\left( i \right)$, as required.
    \end{proof}

    \ex Consider a DTMC with TPM
    \begin{equation*}
        P =
        \begin{bmatrix}
        	0 & \frac{1}{2} & \frac{1}{2} \\
        	\frac{1}{2} & 0 & \frac{1}{2} \\
        	\frac{1}{2} & \frac{1}{2} & 0 \\
        \end{bmatrix}.
    \end{equation*}
    Find the communication classes of this DTMC and determine the period of each state.

    \begin{subproof}[Answer]
        The following is the state transition diagram of the DTMC.
        \begin{center}
            \begin{tikzpicture}[main/.style={draw,circle},node distance={2cm}]
                \node[main](0){$0$};
                \node[main](1)[above right of=0]{$1$};
                \node[main](2)[below right of=1]{$2$};
                \draw[->](0) -- (1);
                \draw[->](0) -- (2);
                \draw[->](1) -- (0);
                \draw[->](1) -- (2);
                \draw[->](2) -- (0);
                \draw[->](2) -- (1);
            \end{tikzpicture}
        \end{center}
        This means $\left\lbrace 0,1,2 \right\rbrace$ is the only communication class. Moreover, note that $0\to 1\to 0$ and $0\to 1\to 2\to 0$ are cycles of lengths $2,3$, respectively, so $d\left( 0 \right)=\gcd\left\lbrace 2,3,\ldots \right\rbrace=1$. It follows from Proposition 3.1 that
        \begin{equation*}
            d\left( 1 \right)=d\left( 2 \right)=d\left( 0 \right)=1. \eqqedsym
        \end{equation*}
    \end{subproof}

    \np As (EX 3.18) shows, it is possible to observe aperiodic behavior even though the main diagonal components of the TPM are zero. Generally, if $d\left( i \right)=k$, then it does not necessarily imply that $P^{\left( k \right)}_{i,i}>0$. Instead, it implies that if the DTMC is in state $i$ at time $0$, then it is impossible to observe the DTMC in state $i$ at time $n\in\N$ is $n$ is not a multiplie of $k$.

    \section{Transience and Recurrence}
    
    \np We desire to take a closer look at the likelihood of a DTMC beginning in some state of returning to that particular state. To that end, let us consider 
    the probability that, starting from state $i$, the first visit of the DTMC to state $j$ occurs at time $n\in\N$, denoted as $f^{\left( n \right)}_{i,j}$.

    \begin{notation}{$f^{\left( n \right)}_{i,j}$}{}
        Consider the setting of (3.20). We write $f^{\left( n \right)}_{i,j}$ to denote 
        \begin{equation*}
            f^{\left( n \right)}_{i,j} = \PP\left( X_n=j,\forall m\in\left\lbrace n-1,\ldots,1 \right\rbrace\left[ X_m\neq j \right]|X_0=i \right)
        \end{equation*}
        for all $i,j\in\N\cup\left\lbrace 0 \right\rbrace$.
    \end{notation}

    \noindent It is clear from Notation 3.10 that 
    \begin{equation*}
        f^{\left( 1 \right)}_{i,j} = \PP\left( X_1=j|X_0=i \right) = P_{i,j},
    \end{equation*}
    where $P$ is the TPM of the DTMC. For every $n\geq 2$, the determination of $f^{\left( n \right)}_{i,j}$ becomes more complicated, and so we desire to construct a procedure which will enable us to compute $f_{i,j}^{\left( n \right)}$. To do so, we consider the quantity $P^{\left( n \right)}_{i,j}$ and condition on the time that the first visit to state $j$ is made:
    \begin{flalign*}
        && P^{\left( n \right)}_{i,j} & = \PP\left( X_n=j|X_0=i \right) && \\ 
        && & = \sum^{n}_{k=1}\PP\left( X_n=j, \text{first visit to $j$ occurs at $k$}|X_0=i \right) && \\
        && & = \sum^{n}_{k=1}\PP\left( X_n=j, X_k=j,X_{k-1}\neq j,\ldots,X_1\neq j|X_0=i \right) && \\
        && & = \sum^{n}_{k=1}\PP\left( X_k=j,X_{k-1}\neq j,\ldots,X_1\neq j|X_0=j \right)\PP\left( X_n=j|X_k=j \right) && \text{by the Markov property} \\
        && & = \sum^{n}_{k=1}f^{\left( k \right)}_{i,j}P^{\left( n-k \right)}_{j,j}. && 
    \end{flalign*} 
    This means
    \begin{equation*}
        P^{\left( n \right)}_{i,j} 
        = f^{\left( n \right)}_{i,j}P^{\left( 0 \right)}_{j,j} + \sum^{n-1}_{k=1} f^{\left( k \right)}_{i,j}P^{\left( n-k \right)}_{j,j} = 
        = f^{\left( n \right)}_{i,j} + \sum^{n-1}_{k=1} f^{\left( k \right)}_{i,j}P^{\left( n-k \right)}_{j,j}.
    \end{equation*}
    Rearranging with respect to $f^{\left( n \right)}_{i,j}$ gives
    \begin{eqbox}[A Recursive Formula for $f^{\left( n \right)}_{i,j}$]
        \begin{equation}
            f^{\left( n \right)}_{i,j} = 
            P^{\left( n \right)}_{i,j} + \sum^{n-1}_{k=1} f^{\left( k \right)}_{i,j}P^{\left( n-k \right)}_{j,j}.
        \end{equation}
    \end{eqbox} 
    When $n\geq 2$, [3.6] yields a recursive means to compute $f^{\left( n \right)}_{i,j}$.

    \begin{notation}{$f_{i,j}$}{}
        Given a DTMC, let $f_{i,j}$ denote
        \begin{equation*}
            f_{i,j} = \PP\left( \exists n\in\N\left[ X_n=j \right]|X_0=i \right).
        \end{equation*}
    \end{notation}

    \noindent Note that
    \begin{flalign*}
        && f_{i,j} & = \sum^{\infty}_{k=1}\PP\left( \exists n\in\N\left[ X_n=j \right], X_k=j, X_{k-1}\neq j,\ldots,X_1\neq j|X_0=i \right) && \\ 
        && & = \sum^{\infty}_{k=1} \PP\left( X_k=j, X_{k-1}\neq j, \ldots, X_1\neq j|X_0=i \right) && \\
        && & = \sum^{\infty}_{k=1} f^{\left( k \right)}_{i,j} && \\
        && & \leq 1.
    \end{flalign*} 
    This leads to the following important concept in the study of Markov chains.

    \begin{definition}{Transient, Recurrent}{State}
        Given a state $i$ of a DTMC, we say $i$ is
        \begin{enumerate}
            \item \emph{transient} if $f_{i,i}<1$; and
            \item \emph{recurrent} if $f_{i,i}=1$.
        \end{enumerate}
    \end{definition}

    \np[Characterizing Transience and Recurrence]In what follows, we proceed to look at alternative ways of characterizing the notions of transience and recurrence. As such, let us first define $M_i$ be a random variable which counts the number of (future) times the DTMC visits state $i$, disregarding the possibility of starting in state $i$ at time $0$. If we assume that $f_{i,i}<1$, then the Markov property and stationary assumption imply that
    \begin{equation}
        \PP\left( M_i=k|X_0=i \right) = \left( \prod^{k}_{n=1}f_{i,i} \right)\left( 1-f_{i,i} \right)=f^k_{i,i}\left( 1-f_{i,i} \right)
    \end{equation}
    for every $k\in\N\cup\left\lbrace 0 \right\rbrace$, as  the DTMC will return to state $i$ $k$ times with probability $f_{i,i}$ and then never return with probability $1-f_{i,i}$. But note that [3.7] is the pmf of $\geodis_f\left( 1-f_{i,i} \right)$ (i.e. $M_i|\left( X_0=i \right)\sim\geodis_f\left( 1-f_{i,i} \right)$). This implies
    \begin{equation*}
        \EE\left( M_i|X_0=i \right) = \frac{1-\left( 1-f_{i,i} \right)}{1-f_{i,i}} = \frac{f_{i,i}}{1-f_{i,i}}
    \end{equation*}
    since $f_{i,i}<1$. On the other hand, if $f_{i,i}=1$, then $\PP\left( M_i>k|X_0=i \right)=1$ for all $k\in\N$, implying that
    \begin{equation*}
        \EE\left( M_i|X_0=i \right)=\infty.
    \end{equation*}
    To obtain another characterization, we may define a sequence of indicator random variables $\left( A_{n} \right)^{\infty}_{n=1}$ by
    \begin{equation*}
        A_n = 
        \begin{cases} 
            0 & \text{if $X_n\neq i$}\\
            1 & \text{if $X_n=i$}
        \end{cases}
    \end{equation*}
    for all $n\in\N$. With this definition,
    \begin{equation*}
        M_i = \sum^{\infty}_{n=1}A_n.
    \end{equation*}
    This means
    \begin{flalign*}
        && \EE\left( M_i|X_0=i \right)&=\EE\left( \sum^{\infty}_{n=1}A_n|X_0=i \right) = \sum^{\infty}_{n=1}\EE\left( A_n|X_0=i \right) && \\ 
        && & = \sum^{\infty}_{n=1} 0\cdot\PP\left( A_n=0|X_0=i \right)+1\cdot\PP\left( A_n=1|X_0=i \right) = \sum^{\infty}_{n=1}\PP\left( X_n=i|X_0=i \right) && \\
        && & =\sum^{\infty}_{n=1}P^{\left( n \right)}_{i,i}.
    \end{flalign*} 
    We summarize our characterizations into the following proposition.

    \clearpage
    \begin{prop}{Characterizations of Transience}
        Let $i$ be a state of a DTMC. The following are equivalent.\footnote{Of course, negations of (b), (c) are characterizations of recurrence.}
        \begin{enumerate}
            \item $i$ is transient.
            \item $\EE\left( M_i|X_0=i \right)$ is finite, where $M_i$ is the number of (future) times the DTMC visits state $i$.
            \item The series $\sum^{\infty}_{n=1}P^{\left( n \right)}_{i,i}$ is convergent.
        \end{enumerate}
    \end{prop}

    \noindent In other words, a transient state will only be visited \textit{finitely often}.

    \begin{prop}{Communication Preserves Recurrence}
        Let $i,j$ be states that communicate. Then $i$ is recurrent if and only if $j$ is recurrent.
    \end{prop}

    \begin{proof}
        It suffices to show that when $i$ is recurrent, then so is $j$. So assume that $i$ is recurrent. Since $i\lra j$, there exists $m,n\in\N\cup\left\lbrace 0 \right\rbrace$ such that 
        \begin{equation*}
            P_{i,j}^{\left( m \right)} , P^{\left( n \right)}_{j,i}>0.
        \end{equation*}
        Also, since $i$ is recurrent, we know that the series $\sum^{\infty}_{k=1}P^{\left( k \right)}_{i,i}$ is divergent. Now, note that
        \begin{equation*}
            P^{\left( n+k+m \right)}_{j,j} \geq P^{\left( n \right)}_{j,i}P^{\left( k \right)}_{i,i}P^{\left( m \right)}_{i,j} 
        \end{equation*}
        for every $k\in\N$. This means the series
        \begin{equation*}
            \sum^{\infty}_{l=n+m+1} P_{j,j}^{\left( l \right)} = \sum^{\infty}_{k=1} P_{j,j}^{\left( n+k+m \right)} = P^{\left( n \right)}_{j,i}P^{\left( m \right)}_{i,j}\sum^{\infty}_{k=1}P^{\left( k \right)}_{i,i}
        \end{equation*}
        is divergent, since $P^{\left( m \right)}_{i,j},P^{\left( n \right)}_{j,i}>0$, so $\sum^{\infty}_{l=1}P^{\left( l \right)}_{j,j}$ is also divergent. Thus $j$ is recurrent, as required.
    \end{proof}

    \begin{prop}{}
        If $i,j$ are states of a DTMC that communicates and $i$ is recurrent, then
        \begin{equation*}
            f_{i,j} = 1.
        \end{equation*}
    \end{prop}

    \begin{proof}
        We may assume $i\neq j$. Since $i\lra j$ and $i$ is recurrent, $j$ is recurrent by Proposition 3.3. This means $f_{j,j}=1$. To prove $f_{i,j}=1$, suppose $f_{i,j}<1$ for the sake of contradiction. Since $i\lra j$, let
        \begin{equation*}
            n_i = \min\left\lbrace n\in\N: P^{\left( n \right)}_{j,i}>0 \right\rbrace.
        \end{equation*}
        That is, each time the DTMC visits to state $j$, there is a nonzero probability $P^{\left( n_i \right)}_{j,i}>0$ of being in state $i$ $n_i$ time units later. Since we assumed $f_{i,j}<1$, then this means that the probability of returning to state $j$ after visiting $i$ in the future is not guaranteed, as $1-f_{i,j}>0$. Therefore, we have
        \begin{equation*}
            1-f_{j,j} = \PP\left( \forall n\in\N\left[ X_n\neq j \right]|X_0=j \right) \geq \underbrace{P^{\left( n_i \right)}_{j,i}}_{>0}\underbrace{\left( 1-f_{i,j} \right)}_{>0} > 0,
        \end{equation*}
        so $f_{j,j}<1$, which is our desired contradiction. Thus $f_{i,j}=1$, as required.
    \end{proof}

    \begin{prop}{}
        Every finite-state DTMC has at least one recurrent state.
    \end{prop}

    \begin{proof}
        We may assume that $\mS = \left\lbrace 0,\ldots,N \right\rbrace$ for some $N\in\N$ is the state space of the DTMC. Assume that every state is transient for the sake of contradiction. For each $i\in\mS$, since we assumed $i$ is transient, $f_{i,i}<1$. This means that, after a finite amount of time, $T_i$, state $i$ will not be visited again. Consequently, after a finite amount of time
        \begin{equation*}
            T = \max_{i\in\mS}T_i,
        \end{equation*}
        has gone by, none of the states will be visited ever again. However, the DTMC must be in some state after $T$ units of time, so we obtain a contradiction. Thus there is a recurrent state of the DTMC.
    \end{proof}

    \begin{cor}{}
        Every irreducible finite-state DTMC is recurrent.\footnote{We say a DTMC is \emph{recurrent} if every state is recurrent.}
    \end{cor}	

    \ex Consider the DTMC with TPM
    \begin{equation*}
        P = 
        \begin{bmatrix}
        	0 & 1 & 0 & 0 \\
        	0 & 0 & 1 & 0 \\
        	0 & 0 & 0 & 1 \\
        	0.5 & 0 & 0.5 & 0 \\
        \end{bmatrix}.
    \end{equation*}
    Determine whether each state is transient or recurrent.

    \begin{subproof}[Answer]
        From (EX 3.13), we know that the DTMC is irreducible. Thus by Corollary 3.5.1, every state of the DTMC is recurrent.
    \end{subproof}

    \begin{prop}{}
        Let $i,j$ be states of a DTMC. If $i$ is recurrent and $i\nlra j$, then $P^{\left( k \right)}_{i,j}=0$ for every $k\in\N$.
    \end{prop}

    \begin{proof}
        For the sake of contradiction, assume $P^{\left( k \right)}_{i,j}>0$ for some $k\in\N$. Choose
        \begin{equation*}
            k_i = \min\left\lbrace k\in\N: P^{\left( k \right)}_{i,j}>0 \right\rbrace.
        \end{equation*}
        Then
        \begin{equation}
            P^{\left( n \right)}_{j,i} = 0
        \end{equation}
        for every $n\in\N$, since otherwise $i\lra j$. However, this means the DTMC has a nonzero probability of at least $P^{\left( k_i \right)}_{i,j}$ of never returning to state $i$, by the minimality of $k_i$ and [3.8]. This is a contradiction, so we conclude that $P^{\left( k \right)}_{i,j}=0$ for all $k\in\N$.
    \end{proof}

    \ex Consider a DTMC with TPM
    \begin{equation*}
        P = 
        \begin{bmatrix}
        	\frac{1}{3} & \frac{2}{3} & 0 & 0 \\
        	\frac{1}{2} & \frac{1}{4} & \frac{1}{8} & \frac{1}{8} \\
        	0 & 0 & 1 & 0 \\
        	\frac{3}{4} & \frac{1}{4} & 0 & 0 \\
        \end{bmatrix}.
    \end{equation*}
    Determine whether each state is transient or recurrent.

    \begin{subproof}[Answer]
        From (EX 3.14), we know that $\left\lbrace 0,1,3 \right\rbrace, \left\lbrace 2 \right\rbrace$ are the communication classes of the DTMC. Now observe that $P^{\left( n \right)}_{2,2} = 1$ for every $n\in\N$, so the series
        \begin{equation*}
            \sum^{\infty}_{n=1}P^{\left( n \right)}_{2,2}
        \end{equation*}
        diverges. So $2$ is recurrent. Since $2\nlra j$ for every $j\in\left\lbrace 0,1,3 \right\rbrace$, it follows that $0,1,3$ are recurrent by Proposition 3.6.
    \end{subproof}

    \np As the above example demonstrates, \textit{once a DTMC enters a recurrent class of states, it can never leave that class}. For this reason, a recurrent class is often referred to as a \textit{closed} class.

    \ex Consider a DTMC with TPM
    \begin{equation*}
        P =
        \begin{bmatrix}
        	\frac{1}{4} & 0 & \frac{3}{4} & 0 \\
        	0 & \frac{1}{3} & 0 & \frac{2}{3} \\
        	0 & 1 & 0 & 0 \\
        	0 & \frac{2}{5} & 0 & \frac{3}{5} \\
        \end{bmatrix}.
    \end{equation*}
    Determine whether each state is transient or recurrent.

    \begin{subproof}[Answer]
        The following is the state transition diagram for the DTMC.
        \begin{center}
            \begin{tikzpicture}[main/.style={draw,circle},node distance={2cm}]
                \node[main](0){$0$};
                \node[main](1)[above right of=0]{$1$};
                \node[main](2)[below right of=1]{$2$};
                \node[main](3)[below right of=0]{$3$};
                \draw[->](0) to [out=270,in=180,looseness=3] (0);
                \draw[->](0) -- (2);
                \draw[->](1) to [out=90,in=0,looseness=3] (1);
                \draw[->](1) -- (3);
                \draw[->](2) -- (1);
                \draw[->](3) to [out=270,in=0,looseness=3] (3);
                \draw[->](3) -- (1);
            \end{tikzpicture}
        \end{center}
        This means the communication classes of the DTMC are $\left\lbrace 0 \right\rbrace, \left\lbrace 1,3 \right\rbrace, \left\lbrace 2 \right\rbrace$. Now observe that
        \begin{equation*}
            \sum^{\infty}_{n=1}P^{\left( n \right)}_{0,0} = \sum^{\infty}_{n=1} \left( \frac{1}{4} \right)^n = \frac{1}{3},
        \end{equation*}
        so $0$ is transient. Moreover,
        \begin{equation*}
            \sum^{\infty}_{n=1}P^{\left( n \right)}_{2,2} = 0
        \end{equation*}
        clearly, so $2$ is transient. It follows from Proposition 3.3, 3.5 that $1,3$ are recurrent.
    \end{subproof}

    \section{Random Walk}

    \ex[Random Walk]Consider a DTMC $\left\lbrace X_n \right\rbrace^{}_{n\in\N\cup\left\lbrace 0 \right\rbrace}$ whose state space is $\Z$. Furthermore, suppose that the TPM $P$ for $\left\lbrace X_n \right\rbrace^{}_{n\in\N\cup\left\lbrace 0 \right\rbrace}$ satisfies
    \begin{flalign*}
        && P_{i,i-1} & = 1-p && \\
        && P_{i,i+1} & = p 
    \end{flalign*} 
    for all $i\in\Z$, where $p\in\left( 0,1 \right)$. As such, $X_n$ can be expressed as
    \begin{equation*}
        X_n = \sum^{n}_{k=0} Y_k,
    \end{equation*}
    where $\left\lbrace Y_k \right\rbrace^{\infty}_{k=0}$ is an independent collection of random variables with $Y_0=x_0$ and
    \begin{flalign*}
        && \PP\left( Y_k = -1 \right) & = 1-p && \\
        && \PP\left( Y_k=1 \right) & =p
    \end{flalign*} 
    for all $k\in\N$. Characterize the behavior of this DTMC in terms of its communication classes, periodicity, and recurrence.

    \begin{subproof}[Answer]
        Observe that the state transition diagram of the DTMC is the following.
        \begin{center}
            \begin{tikzpicture}[main/.style={draw,circle},node distance={2cm}]
                \node[main](0){$0$};
                \node[main](1)[right of=0]{$1$};
                \node[main](2)[right of=1]{$2$};
                \node[main](-1)[left of=0]{$-1$};
                \node[main](-2)[left of=-1]{$-2$};
                \draw[->](0) -- (1);
                \draw[->](0) -- (-1);
                \draw[->](1) -- (2);
                \draw[->](1) -- (0);
                \draw[->](2) -- (1);
                \draw[->](-1) -- (0);
                \draw[->](-1) -- (-2);
                \draw[->](-2) -- (-1);
                \draw[fill](4.75,0) circle (0.3pt);
                \draw[fill](5,0) circle (0.3pt);
                \draw[fill](5.25,0) circle (0.3pt);
                \draw[fill](-4.75,0) circle (0.3pt);
                \draw[fill](-5,0) circle (0.3pt);
                \draw[fill](-5.25,0) circle (0.3pt);
            \end{tikzpicture}
        \end{center}
        Since $p\in\left( 0,1 \right)$, all states communicate with each other, which means $\Z$ is the communication class of the DTMC, and the DTMC is irreducible. Furthermore, starting from state $0$, the DTMC cannot visit $0$ again in an odd number of transitions. On the other hand, $0\to 2\to 0$ is a cycle of length $2$. This means the period of $0$ is $2$. Since periodicity is a class property, it follows that
        \begin{equation*}
            d\left( i \right)=2
        \end{equation*}
        for all $i\in\Z$. Finally, to determine recurrence of state $0$, note that
        \begin{equation*}
            \sum^{\infty}_{m=1}P^{\left( m \right)}_{0,0} = \sum^{\infty}_{n=1}P^{\left( 2n \right)}_{0,0} = \sum^{\infty}_{n=1} \binom{2n}{n}p^n\left( 1-p \right)^n
        \end{equation*}
        since $P^{\left( m \right)}_{0,0}=0$ for all odd $m\in\N$. Now note that
        \begin{flalign*}
            && \lim_{n\to\infty} \frac{P^{\left( 2\left( n+1 \right) \right)}}{P^{\left( 2n \right)}}& =\lim_{n\to\infty} \frac{\binom{2n+2}{n+1}p^{\left( n+1 \right)}\left( 1-p \right)^{n+1}}{\binom{2n}{n}p^n\left( 1-p \right)^n} = \lim_{n\to\infty} \frac{\frac{\left( 2n+2 \right)!}{\left( n+1 \right)!\left( n+1 \right)!}p^{n+1}\left( 1-p \right)^{n+1}}{\frac{2n!}{n!n!}p^n\left( 1-p \right)^n} &&\\
            && & = \lim_{n\to\infty} \frac{\left( 2n+2 \right)\left( 2n+1 \right)}{\left( n+1 \right)\left( n+1 \right)} p\left( 1-p \right) = \lim_{n\to\infty} 4p\left( 1-p \right) = 4p\left( 1-p \right).
        \end{flalign*} 
        This means, when $p\neq \frac{1}{2}$,
        \begin{equation*}
            \lim_{n\to\infty} \frac{P^{\left( 2\left( n+1 \right) \right)}}{P^{\left( 2n \right)}} = 4p\left( 1-p \right)<1,
        \end{equation*}
        so the series $\sum^{\infty}_{n=1}P^{\left( 2n \right)}_{0,0}$ converges by the ratio test. In case $p=\frac{1}{2}$, 
        \begin{equation*}
            \lim_{n\to\infty} \frac{P^{\left( 2\left( n+1 \right) \right)}}{P^{\left( 2n \right)}} = 1,
        \end{equation*}
        so the ratio test is inconclusive. To determine what is happening when $p=\frac{1}{2}$, we consider an alternative approach. Recall that
        \begin{equation*}
            f_{i,j} = \PP\left( \exists n\in\N\left[ P_n=j \right]|X_0=i \right)
        \end{equation*}
        For convenience, let $q=1-p$. We condition on the state of the DTMC at time 1:
        \begin{flalign*}
            && f_{0,0} = & \,\,\PP\left( \exists n\in\N\left[ X_n=0 \right]|X_0=0 \right) && \\ 
            && = & \,\,\PP\left( X_1=-1|X_0=0 \right)\PP\left( \exists n\geq 2\left[ X_n=0 \right]|X_1=-1,X_0=0 \right) && \\
            && & + \PP\left( X_1=1|X_0=0 \right)\PP\left( \exists n\geq 2\left[ X_n=0 \right]|X_1=1,X_0=0 \right) && \\
            && = & \,\,\PP\left( X_1=-1|X_0=0 \right)\PP\left( \exists n\geq 2\left[ X_n=0 \right]|X_1=-1 \right) && \\
            && & + \PP\left( X_1=1|X_0=0 \right)\PP\left( \exists n\geq 2\left[ X_n=0 \right]|X_1=1 \right) && \text{by the Markov property}\\
            && = & \,\,qf_{-1,0}+pf_{1,0}.
        \end{flalign*} 
        If we let $E$ represent the event that the DTMC ever makes a future visit to state $0$, then
        \begin{equation*}
            E = \bigcup^{\infty}_{i=1} \left\lbrace X_i = 0 \right\rbrace.
        \end{equation*}
        So
        \begin{flalign*}
            && f_{1,0} & = \PP\left( F|X_1=0 \right) && \\
            && = &\,\,\PP\left( F\cap \left\lbrace X_1=0 \right\rbrace | X_0=1\right) + \PP\left( F\cap\left\lbrace X_1=2 \right\rbrace|X_0=1 \right) && \\
            && = &\,\,\underbrace{\PP\left( F|X_1=0,X_0=1 \right)}_{=1}\PP\left( X_1=0|X_0=1 \right) && \\
            && & + \PP\left( F|X_1=2,X_0=1 \right)\PP\left( X_1=2|X_0=1 \right) && \\
            && = &\,\,\PP\left( X_1=0|X_0=1 \right) + \PP\left( F|X_1=2 \right)\PP\left( X_1=2|X_0=1 \right) && \substack{\text{by the Markov}\\\text{property}}\\
            && = &\,\,q + p\PP\left( E|X_1=2 \right) && \\
            && = &\,\,q + p\PP\left( \bigcup^{\infty}_{i=2}\left\lbrace X_i=0 \right\rbrace\union\left\lbrace X_1=0 \right\rbrace|X_1=2 \right) && \\
            && = &\,\,q + p\PP\left( \bigcup^{\infty}_{i=2}\left\lbrace X_i=0 \right\rbrace|X_1=2 \right) && \substack{\text{since}\\\PP\left( X_1=0|X_1=2 \right)=0}\\
            && = &\,\,q + p\PP\left( E | X_0=2 \right) && \substack{\text{by the stationary}\\\text{assumption}} \\
            && = &\,\,q + pf_{2,0}.
        \end{flalign*} 
        Furthermore, it is clear from the defintion of the DTMC that
        \begin{equation*}
            f_{2,0} = f_{2,1}f_{1,0} = f_{1,0}^{2},
        \end{equation*}
        where the last equality holds by the stationary assumption. Hence we obtain that
        \begin{equation*}
            f_{1,0} = \left( 1-p \right)+pf_{1,0}^{2},
        \end{equation*}
        and by rearranging in terms of $f_{1,0}$ gives
        \begin{equation*}
            pf^{2}_{1,0} - f_{1,0} + 1 - p = 0.
        \end{equation*}
        By applying the quadratic formula,
        \begin{equation}
            f_{1,0} = \frac{1\pm\sqrt{1-4p\left( 1-p \right)}}{2p} = 1,
        \end{equation}
        since $p=\frac{1}{2}$. By symmetry, $f_{-1,0} = 1$. This means
        \begin{equation*}
            f_{0,0} = \left( 1-p \right)f_{-1,0}+pf_{1,0} = \frac{1}{2} + \frac{1}{2} = 1,
        \end{equation*}
        so $0$ is recurrent. Thus every state of the DTMC is recurrent, since recurrence is a class property.
    \end{subproof}

    \noindent Note that, when $p\neq \frac{1}{2}$, the first equality in [3.9] yields
    \begin{equation*}
        f_{1,0} \in \left\lbrace \frac{1+\left| 2p-1 \right|}{2p}, \frac{1-\left| 2p-1 \right|}{2p} \right\rbrace.
    \end{equation*}
    We may assume $p<\frac{1}{2}$. This means $2p-1<0$, so
    \begin{flalign*}
        && \frac{1-\left( 1-2p \right)}{2p} & = 1 && \\
        && \frac{1+\left( 1-2p \right)}{2p} & > 1 && 
    \end{flalign*} 
    which means $f_{1,0} = 1$, since a probability cannot be greater than $1$. In other words,
    \begin{equation*}
        f_{1,0} = \frac{1-\left| 1-2p \right|}{2p}.
    \end{equation*}
    Moreover, it can be shown that
    \begin{equation*}
        f_{-1,0} = \frac{1-\left| 1-2p \right|}{2\left( 1-p \right)}.
    \end{equation*}
    Thus we obtain that
    \begin{equation*}
        f_{0,0} = \left( 1-p \right) \frac{1-\left| 1-2p \right|}{2\left( 1-p \right)} + p \frac{1-\left( 1-2p \right)}{2p} = 1-\frac{1}{2} \left( 2-4p \right) = 1-\left( 1-2p \right) = 2p < 1
    \end{equation*}
    when $p<\frac{1}{2}$, which is consistent with our earlier finding that the DTMC is transient when $p\neq \frac{1}{2}$. In general, we have the following formula:
    \begin{eqbox}[General Formula for $f_{0,0}$ of a Random Walk]
        \begin{equation}
            f_{0,0} = 2\min\left\lbrace p,1-p \right\rbrace.
        \end{equation}
    \end{eqbox} 

    \section{Limiting Behaviors of DTMCs}

    \np[Motivation]The concepts of periodicity and recurrence play an important role in characterizing the limiting behavior of a DTMC. That is, we desire to determine the behavior of the DTMC $\left( X_{n} \right)^{\infty}_{n=1}$ as $n\to\infty$.

    \begin{prop}{}
        For any state $i,j$ of a DTMC, if $j$ is transient, then
        \begin{equation*}
            \lim_{n\to\infty} P^{\left( n \right)}_{i,j} = 0.
        \end{equation*}
    \end{prop}

    \begin{proof}
        Recall that
        \begin{equation*}
            f_{i,j}^{\left( n \right)} = \PP\left( X_n=j, \forall m\in\left\lbrace n-1,\ldots,1 \right\rbrace\left[ X_m\neq j \right]|X_0=i \right)
        \end{equation*}
        and that
        \begin{equation*}
            f_{i,j} = \PP\left( \exists n\in\N \left[ X_n = j \right] | X_0=i \right).
        \end{equation*}
        These quantities are related by
        \begin{equation*}
            f_{i,j} = \sum^{\infty}_{n=1} f^{\left( n \right)}_{i,j}.
        \end{equation*}
        Moreover, 
        \begin{equation*}
            P^{\left( n \right)}_{i,j} = \sum^{n}_{k=1} f^{\left( k \right)}_{i,j}P^{\left( n-k \right)}_{j,j}.
        \end{equation*}
        This means
        \begin{flalign*}
            && \sum^{\infty}_{n=1} P^{\left( n \right)}_{i,j} & = \sum^{\infty}_{n=1} \sum^{n}_{k=1} f^{\left( k \right)}_{i,j}P^{\left( n-k \right)}_{j,j} = \sum^{\infty}_{k=1} \sum^{\infty}_{n=k} f^{\left( k \right)}_{i,j} P^{\left( n-k \right)}_{j,j} && \\
            && & = \sum^{\infty}_{k=1} f^{\left( k \right)}_{i,j} \sum^{\infty}_{n=k} P^{\left( n-k \right)}_{j,j} = \sum^{\infty}_{k=1} f^{\left( k \right)}_{i,j} \sum^{\infty}_{l=0} P^{\left( l \right)}_{j,j} && \\
            && & = f_{i,j} \left( 1 + \sum^{\infty}_{l=1} P^{\left( l \right)}_{j,j} \right) .
        \end{flalign*} 
        But note that $\sum^{\infty}_{l=1} P^{\left( l \right)}_{j,j}$ is convergent, as $j$ is transient. It follows that $\sum^{\infty}_{n=1} P^{\left( n \right)}_{i,j}$ is also convergent, which implies
        \begin{equation*}
            \lim_{n\to\infty} P^{\left( n \right)}_{i,j} = 0. \eqedsym
        \end{equation*}
    \end{proof}

    \np[Mean Recurrent Time]It is worthwhile to determine a set of conditions which ensure the \textit{nice} limiting behavior. To ascertain when such conditions exist, we need to distinguish between two kinds of recurrences. Suppose that we are given a DTMC $\left( X_{n} \right)^{\infty}_{n=1}$ and let
    \begin{equation*}
        N_i = \min\left\lbrace n\in\N: X_n=i \right\rbrace
    \end{equation*}
    for all recurrent state $i$. Clearly the conditional random variable $N_i|\left( X_0=i \right)$ takes on values in $\N$. Moreover, the conditional pmf is given by
    \begin{equation*}
        p_{N_i|X_0}\left( n|i \right) = \PP\left( N_i=n|X_0=i \right) = f^{\left( n \right)}_{i,i}
    \end{equation*}
    for all $n\in\N$. We observe that this indeed is a pmf since
    \begin{equation*}
        \sum^{\infty}_{n=1} f^{\left( n \right)}_{i,i} = f_{i,i} = 1,
    \end{equation*}
    as $i$ is recurrent. This leads to the introduction of the following important quantity.

    \begin{definition}{Mean Recurrent Time}{of a Recurrent State}
        Consider the setting of (3.28). We define the \emph{mean recurrent time} of $i$, denoted as $m_i$, by
        \begin{equation*}
            m_i = \EE\left( N_i|X_0=i \right).
        \end{equation*}
    \end{definition}

    \noindent It is immediate from the construction that the following equation holds:
    \begin{eqbox}[Formula for $m_i$]
        \begin{equation}
            m_i = \sum^{\infty}_{n=1} nf^{\left( n \right)}_{i,i}.
        \end{equation}
    \end{eqbox} 
    \begin{enumerate}
        \item Note that we may have $m_i=\infty$, in case the right-hand-side of [3.11] diverges to infinity. 
        \item In words, $m_i$ represents the \textit{average time} it takes the DTMC to make successive visits to state $i$. 
    \end{enumerate}
    Two notions of recurrence can now be defined based on the value of $m_i$.

    \begin{definition}{Positive, Null}{Recurrence}
        Let $i$ be a recurrent state of a DTMC. We say $i$ is
        \begin{enumerate}
            \item \emph{positive} recurrent if $m_i<\infty$; and
            \item \emph{null} recurrent if $m_i=\infty$.
        \end{enumerate}
    \end{definition}

    \noindent We shall admit the following facts about positive and null recurrences without any proof, as their proof is lengthy and beyond the scope of this note.

    \clearpage
    \begin{fact}{}
        Positive recurrence is a class property. That is, given states $i,j$ that communicate, $i$ is positive recurrent if and only if $j$ is.
    \end{fact}

    \begin{fact}{}
        Every recurrent state in a finite-state DTMC is positive recurrent.
    \end{fact}

    \begin{definition}{Ergodic}{State}
        A state of a DTMC is called \emph{ergodic} if positive recurrent and aperiodic.
    \end{definition}

    \begin{definition}{Stationary Distribution}{of a DTMC}
        Let $p:\N\cup\left\lbrace 0 \right\rbrace\to\left[ 0,1 \right]$ be a pmf. We say $p$ is a \emph{stationary distribution} (or \emph{invariant distribution}, \emph{steady-state distribution}) of a DTMC if
        \begin{equation*}
            p\left( j \right) = \sum^{\infty}_{i=0} p\left( i \right)P_{i,j}
        \end{equation*}
        for all $j\in\N\cup\left\lbrace 0 \right\rbrace$.\footnote{We usually denote $p$ as a sequence: $p=\left( p_{i} \right)^{\infty}_{i=0}$.}
    \end{definition}

    \np[Stationary Distribution]Suppose that $p$ is a stationary distribution of a DTMC.
    \begin{enumerate}
        \item If we use the notation
            \begin{equation*}
                p = \left( p_{i} \right)^{\infty}_{i=0},
            \end{equation*}
            then Def'n 3.16 can be represented in matrix form as
            \begin{flalign*}
                && p^{T}e & = 1 && \\ 
                && p^{T} & = p^{T}P,
            \end{flalign*}
            where $e=\left( 1 \right)^\infty_{i=0}$ denotes the sequence whose terms are all $1$.\footnote{We shall use column notation for vectors. That is, whenever we are using sequences as vectors, we are using them as \textit{column} vectors.}
        \item Suppose that the initial conditions of the DTMC $\left( X_{n} \right)^{\infty}_{n=0}$ are given by
            \begin{equation*}
                \alpha_0 = p.
            \end{equation*}
            As a result, we have that
            \begin{equation*}
                \alpha_{0,j} = \PP\left( X_0=j \right) = p_j
            \end{equation*}
            for all $j\in\N\cup\left\lbrace 0 \right\rbrace$. Now, for any $j\in\N\cup\left\lbrace 0 \right\rbrace$, note that
            \begin{equation*}
                \alpha_{1,j} = \PP\left( X_1=j \right) = \sum^{\infty}_{i=0}\alpha_{0,i} P_{i,j} = \sum^{\infty}_{i=0}p_iP_{i,j} = p_j = \alpha_{0,j}.
            \end{equation*}
            This indicates $X_1\sim X_0$, when the initial conditions are set by a stationary distribution. It follows inductively that each $X_i$, $i\in\N$, is identically distributed to $X_0$. In words, if a DTMC is started according to a stationary distribution, then the probability of being in a given state remains unchanged (i.e. stationary) over time. This explains the nomenclature \textit{stationary}.
        \item Stationary distribution is not necessarily unique. This happens when a DTMC has more than one positive recurrent communication class. In particular, some examples have an \textit{infinite} number of stationary distributions.
    \end{enumerate}
    We are also going to accept the following known facts without any formal justification.

    \clearpage
    \begin{fact}{}
        If a DTMC does not have a positive recurrent state, then there is no stationary distribution.
    \end{fact}

    \begin{fact}{}
        Given any irreducible DTMC, the following are equivalent.
        \begin{enumerate}
            \item The DTMC is positive recurrent.
            \item There exists a stationary distribution of the DTMC.
        \end{enumerate}
    \end{fact}

    \np[Basic Limit Theorem]We are now in position to state the fundamental limiting theorem for DTMCs, generally referred to as the \textit{basic limit theorem}.

    \begin{theorem}{Basic Limit Theorem (BLT)}
        Let $\left( X_{n} \right)^{\infty}_{n=0}$ be a DTMC. If $\left( X_{n} \right)^{\infty}_{n=0}$ is irreducible, recurrent, and aperiodic, then
        \begin{equation*}
            \lim_{n\to\infty} P^{\left( n \right)}_{i,j} = \frac{1}{m_j}
        \end{equation*}
        for all $i,j\in\N\cup\left\lbrace 0 \right\rbrace$. Furthermore, if the recurrence is positive, then $\left( \pi_{j} \right)^{\infty}_{j=0} = \left( \frac{1}{m_j} \right)^{\infty}_{j=0}$ is the unique positive solution to the system of linear equations defined by\footnote{For the definition of $m_j$, the mean recurrent time, see Def'n 3.13.}
        \begin{flalign*}
            && \pi_j & = \sum^{\infty}_{i=0}\pi_i P_{i,j} \hspace{2cm}\forall j\in\N\cup\left\lbrace 0 \right\rbrace && \\ 
            && \sum^{\infty}_{j=0} \pi_j & = 1,
        \end{flalign*}
    \end{theorem}

    \noindent A formal proof of the BLT is beyond the scope of this note. But here are some remarks.
    \begin{enumerate}
        \item If we denote $\pi=\left( \pi_{j} \right)^{\infty}_{j=0}$, then the system of linear inequalities in the BLT can be succintly written as
            \begin{flalign*}
                && \pi^{T} & = \pi^{T} P && \\ 
                && \pi^{T}e & = 1. 
            \end{flalign*}
            In particular, if a DTMC is irreducible and ergodic, then the BLT states that the limiting probability distribution is the unique stationary distribution.
        \item When a DTMC has a finite number of states, say $N+1\in\N$ states, the system
            \begin{flalign*}
                && \pi^{T} & = \pi^{T} P && \\ 
                && \pi^{T}e & = 1
            \end{flalign*}
            has $N+2$ equations but $N+1$ indeterminates, of which a unique solution must exist. In fact, the first $N+1$ equations (i.e. $\pi^{T}=\pi^{T}P$) are linearly dependent, so we can \textit{drop any one} of the equations and solve the remaining system to obtain the unique solution.
        \item If the conditions of the BLT are satisfied and state $j$ is null recurrent, then $\pi_j = 0$, interestingly similar to the limiting behavior of a transient state.
    \end{enumerate}

    \clearpage
    \ex Consider a DTMC with TPM
    \begin{equation*}
        P =
        \begin{bmatrix}
        	\frac{1}{2} & \frac{1}{2} & 0 \\
        	\frac{1}{2} & \frac{1}{4} & \frac{1}{4} \\
        	0 & \frac{1}{3} & \frac{2}{3} \\
        \end{bmatrix}.
    \end{equation*}
    Find the limiting probabilities for this DTMC.
    
    \begin{subproof}[Answer]
        Note that the DTMC is irreducible, aperiodic, and positive recurrent. Therefore, the limiting probability distribution
        \begin{equation*}
            \pi = \left( \pi_0,\pi_1,\pi_2 \right)
        \end{equation*}
        exists by the BLT. To find $\pi$, we solve the following system of linear equalities
        \begin{equation}
            \pi^{T} = \pi^{T}P
        \end{equation}
        subject to $\pi_1+\pi_2+\pi_3=1$. Note that [3.12] is equivalent to
        \begin{equation*}
            \pi = P^{T}\pi.
        \end{equation*}
        In other words, $\pi$ is the eigenvector of $P^{T}$ whose sum of entries is $1$. Then by employing the techniques from MATH 146, we find that 
        \begin{equation*}
            \pi = \begin{bmatrix} \frac{4}{11} \\ \frac{4}{11} \\ \frac{3}{11} \end{bmatrix} . \eqqedsym
        \end{equation*}
    \end{subproof}

    \begin{definition}{Doubly Stochastic}{Matrix}
        Let $P\in M_{n\times n}(\R)$ be a matrix.\footnote{$n\in\N\cup\left\lbrace \infty \right\rbrace$.} If both $P, P^{T}$ are stochastic, then we say $P$ is \emph{doubly stochastic}.
    \end{definition}

    \begin{prop}{}
        Suppose that a fintite-state DTMC with state $S = \left\lbrace 0,\ldots,N-1 \right\rbrace$ is irreducible and aperiodic. If the associated TPM $P$ is doubly stochastic, then the limiting probabilities $\pi_0,\ldots,\pi_{N-1}$ exist and are given by
        \begin{equation*}
            \pi_j = \frac{1}{N}
        \end{equation*}
        for all $j\in\left\lbrace 0,\ldots,N-1 \right\rbrace$.
    \end{prop}

    \begin{proof}
        We are given that the DTMC is irreducible and aperiodic. Moreover, every finite irreducible DTMC is positive recurrent, so a unique limiting probability distribution $\pi = \left( \pi_{j} \right)^{N-1}_{j=0}$ exists by the BLT. To determine the limiting distribution, let us propose that
        \begin{equation*}
            \pi = \left( \frac{1}{N} \right)^{N-1}_{j=0}
        \end{equation*}
        is a solution to the system of linear equalities
        \begin{flalign*}
            && \pi^{T}P & = \pi^{T} && \\ 
            && \pi^{T}e & = 1.
        \end{flalign*}
        Clearly the second equation is satisfied:
        \begin{equation*}
            \pi^{T}e = \begin{bmatrix} \pi_0 & \cdots & \pi_{N-1} \end{bmatrix} \begin{bmatrix} 1\\\vdots\\1 \end{bmatrix} = \sum^{N-1}_{j=0} \pi_j = \sum^{N-1}_{j=0} \frac{1}{N} = 1.
        \end{equation*}
        Moreover, for all $j\in\left\lbrace 0,\ldots,N-1 \right\rbrace$, note that
        \begin{equation*}
            \sum^{N-1}_{k=0} \pi_k P_{k,j} = \sum^{N-1}_{k=0} \frac{1}{N} P_{k,j} = \frac{1}{N} \underbrace{\sum^{N-1}_{k=0}P_{k,j}}_{=1} = \frac{1}{N} = \pi_j,
        \end{equation*}
        where the equality $\sum^{N-1}_{k=0}P_{k,j} = 1$ follows from the fact that $P$ is doubly stochastic. This concludes the proof.
    \end{proof}

    \np[Alternative Interpretation of the Limiting Distribution of a DTMC]The primary interpretation of the limiting distribution of a DTMC $\left( X_{n} \right)^{\infty}_{n=0}$ is that after the process has been in operation for a \textit{long} period of time, the probability of finding the process in state $j$ is $\pi_j$, assuming the conditions of the BLT are met. In such situations, however, another interpretation exists for $\pi_j$: \textit{the long-run mean fraction of time that the process spends in state $j$}. To see that this interpretation is valid, define the sequence of indicator random variables $\left( A_{k} \right)^{\infty}_{k=1}$ as follows:
    \begin{equation*}
        A_k = 
        \begin{cases} 
            0 & \text{if $X_k\neq j$} \\
            1 & \text{if $X_k=j$}
        \end{cases}
    \end{equation*}
    for all $k\in\N$. The fraction of time the DTMC visits state $j$ during the time interval from $1$ to $n$, inclusive, is therefore given by
    \begin{equation*}
        \frac{1}{n} \sum^{n}_{k=1}A_k.
    \end{equation*}
    Now suppose a state $i$ is given and consider the quantity
    \begin{equation*}
        \EE\left( \frac{1}{n} \sum^{n}_{k=1}A_k | X_0=i \right),
    \end{equation*}
    which is interpreted as the mean fraction of time spent in state $j$ during the time interval from $1$ to $n$, inclusive, given that the process starts in state $i$. Note that
    \begin{flalign*}
        && \EE\left( \frac{1}{n}\sum^{n}_{k=1}A_k | X_0=i \right) & = \frac{1}{n} \sum^{n}_{k=1}\EE\left( A_k|X_0=i \right)&& \\ 
        && & = \frac{1}{n} \sum^{n}_{k=1} 0\PP\left( A_k=0|X_0=i \right) + 1\PP\left( A_k=1|X_0=i \right) && \\
        && & = \frac{1}{n} \sum^{n}_{k=1} \PP\left( A_k=1|X_0=i \right) && \\
        && & = \frac{1}{n} \sum^{n}_{k=1} P^{\left( k \right)}_{i,j}.
    \end{flalign*}
    But recall that if $\left( a_{n} \right)^{\infty}_{n=1}\in\R^{\N}$ is such that $\lim_{n\to\infty}a_n = a\in\R$, then $\frac{1}{n}\sum^{\infty}_{n=1}a_n = a$. Now we know that
    \begin{equation*}
        \lim_{n\to\infty} P^{\left( n \right)}_{i,j} = \pi_j
    \end{equation*}
    if the conditions of the BLT are satisfied. Thus we obtain
    \begin{equation*}
        \lim_{n\to\infty}\EE\left( \frac{1}{n} \sum^{n}_{k=1}A_k|X_0=i \right) = \pi_j,
    \end{equation*}
    justifying our interpretation.

    \clearpage
    \np If $\left( X_{n} \right)^{\infty}_{n=0}$ begins in recurrent state $j$, then the DTMC spends one unit of time in $j$ every $N_j$ time units. On average, this amounts to one unit of time in state $j$ every $\EE\left( N_j|X_0=j \right)=m_j$ time units. If the conditions of the BLT are satisfeid, then it makes sense intuitively that
    \begin{equation*}
        \pi_j = \frac{1}{m_j}
    \end{equation*}
    as the BLT specifies. We can produce more formal justification in the positive recurrent case. Let $\left( N_{j}^{\left( n \right)} \right)^{\infty}_{n=1}$ be a sequence of random variables where $N_j^{\left( n \right)}$ represents the number of transitions between the $\left( n-1 \right)$th and $n$th visits into state $j$. By the Markov property and the stationary assumption of the DTMC, $\left( N_{j}^{\left( n \right)} \right)^{\infty}_{n=1}$ is an iid sequence of random variables with common mean $m_j$. Therefore, the long-run fraction of time spent in state $j$ can be viewed as
    \begin{equation*}
        \pi_j = \lim_{n\to\infty} \frac{n}{\sum^{n}_{i=1}N_j^{\left( i \right)}} = \lim_{n\to\infty} \frac{1}{\frac{1}{n}\sum^{n}_{i=1}N_j^{\left( i \right)}} = \frac{1}{m_j},
    \end{equation*}
    where the last equality follows from the SLLN.

    \section{Galton-Watson Branching Process}

    \np We assume that a population of individuals (e.g. people, organisms, free particles, \ldots) evolves in discrete time. Specifically, we define
    \begin{equation*}
        X_n = \text{population of the $n$th generation}
    \end{equation*}
    for all $n\in\N\cup\left\lbrace 0 \right\rbrace$, where $X_0$ is the population of the $0$th (i.e. original) generation.

    We assume that each individual in a generation produces a random number (possibly $0$) of individuals, called \textit{offspring}, which go on and become part of the very next generation. In other words, it is always the offspring of a current generation which go on to form the next generation.

    We further assume that individuals produce offspring independently of all others according to the same probability distribution.
    \begin{notation}{$\alpha_m$}{}
        For all $m\in\N\cup\left\lbrace 0 \right\rbrace$, let
        \begin{equation*}
            \alpha_m = \PP\left( \text{an individual produces $m$ offspring} \right)
        \end{equation*}
    \end{notation}
    In addition, we make two additional assumptions: $\alpha_0\in\left( 0,1 \right)$ and $\alpha_0+\alpha_1<1$.

    \begin{notation}{$Z_i^{\left( j \right)}$}{}
        For each $j\in\N\cup\left\lbrace 0 \right\rbrace$, we write $Z_i^{\left( j \right)}$ to denote the number of offspring produced from individual $i$ in the $j$th generation.
    \end{notation}

    \noindent Due to the independence assumptions, $\left( Z^{\left( j \right)}_{i} \right)^{\infty}_{i=1}$ is an iid sequence of random variables with
    \begin{equation*}
        \alpha_m = \PP\left( Z^{\left( j \right)}_i = m \right)
    \end{equation*}
    for all $j\in\N\cup\left\lbrace 0 \right\rbrace$. Hence we may define the following.

    \begin{notation}{$\mu,\sigma$}{}
        Let $\mu = \EE\left( Z_i^{\left( j \right)} \right), \sigma^{2}=\var\left( Z_i^{\left( j \right)} \right)$ represent to the common mean and variance, respectively, of the number of offspring produced by a single individual.
    \end{notation}

    \noindent Based on the above assumptions, any Galton-Watson process $\left( X_{n} \right)^{}_{n\in\N\cup\left\lbrace 0 \right\rbrace}$ is a stationary DTMC taking values in the state space $\N\cup\left\lbrace 0 \right\rbrace$, since it follows that
    \begin{equation}
        X_n = \sum^{X_{n-1}}_{i=1} Z_i^{\left( n-1 \right)},
    \end{equation}
    implying that the Markov property and stationary assumption are both satisfied. 

    \np[Mean and Variance of a Galton-Watson Process]Since [3.13] infers that $X_n$ is expressible as a \textit{random sum}, we can apply the results of (EX 2.10) to obtain
    \begin{equation*}
        \EE\left( X_n \right) = \mu\EE\left( X_n \right)
    \end{equation*}
    and
    \begin{equation*}
        \var\left( X_n \right)=\sigma^{2}\EE\left( X_{n-1} \right)+\mu^{2}\var\left( X_{n-1} \right)
    \end{equation*}
    for all $n\in\N$. Note that the above equations are not explicit, but recursive. Let us henceforth assume that $X_0=1$ almost surely. As it is understood that $X_0=1$, we will suppress writing the condition $X_0=1$ in all expectations and probabilites will follow. This means
    \begin{equation*}
        \EE\left( X_n \right) = \mu^n
    \end{equation*}
    and 
    \begin{equation*}
        \var\left( X_n \right) = \sigma^{2}\mu^{n-1} \sum^{n-1}_{i=0}\mu^i =
        \begin{cases} 
            n\sigma^{2} & \text{if $\mu=1$}\\
            \sigma^{2}\mu^{n-1} \left( \frac{1-\mu^n}{1-\mu} \right) & \text{if $\mu\neq 1$}
        \end{cases}
    \end{equation*}
    for all $n\in\N\cup\left\lbrace 0 \right\rbrace$.

    \np[Limiting Probability]In a Galton-Watson branching process, we remakr that $P_{0,0}=1$, since state $0$ is obviously an absorbing state (i.e. no individuals from which offsprings can be born). If we consider state $i\in\N$, then we can easily show that $i$ is transient as follows.

    \begin{subproof}
        Note that $0\nlra i$. But $P_{i,0} = \alpha_0^i > 0$, since $\alpha_0>0$. Thus by (the constrapositive) of Proposition 3.6 that $i$ is transient.
    \end{subproof}

    \noindent Thus, since state 0 is recurrent and states $1,2,\ldots$ are transient, exactly one of the following happens.
    \begin{enumerate}
        \item The population will die out eventually.
        \item The population will grow indefinitely.
    \end{enumerate}

    \begin{notation}{$\pi_0$}{}
        Let $\pi_0$ denote the limiting probability dies out:
        \begin{equation*}
            \pi_0 = \lim_{n\to\infty} \PP\left( X_n=0 \right).
        \end{equation*}
    \end{notation}

    \noindent The limiting behaviors can be characterized in terms of $\mu$.
    \begin{itemize}
        \item \textit{Case 1. Suppose $\mu<1$.} This is referred to as the \textit{subcritical case}. Clearly, as $n$ grows to infinity, both
            \begin{equation*}
                \EE\left( X_n \right) = \mu^n, \var\left( X_n \right) = \sigma^{2}\mu^{n-1}\left( \frac{1-\mu^n}{1-\mu} \right)
            \end{equation*}
            converge to $0$. Therefore, we expect that $\pi_0=1$. To show this formally, note that
            \begin{equation*}
                \mu^n = \EE\left( X_n \right) = \sum^{\infty}_{j=1}j\PP\left( X_n=j \right) \geq \sum^{\infty}_{j=1}\PP\left( X_n=j \right) = \PP\left( X_n\geq 1 \right) = 1-\PP\left( X_n=0 \right).
            \end{equation*}
            This implies that $1-\mu^n\leq\PP\left( X_n=0 \right)\leq 1$. Taking the limit leads to
            \begin{equation*}
                1 = \lim_{n\to\infty} \left( 1-\mu^n \right) \leq \lim_{n\to\infty} \PP\left( X_n=0 \right) = \pi_0 \leq 1,
            \end{equation*}
            so $\pi_0=1$.

        \item \textit{Case 2. Suppose $\mu\geq 1$.} By conditioning on the number of offspring produced by the single individual present in the population at time $0$, we obtain
            \begin{equation*}
                \pi_0 = \PP\left( \text{population dies out} \right) = \sum^{\infty}_{j=0} \PP\left( \text{population dies out}|X_1=j \right)\alpha_j.
            \end{equation*}
            However, with $X_1=j$, the population will eventaully die out if and only if each of the $j$ families started by the members of the first generation eventaully dies out. As each family is assumed to act independently, and since the probability that any particular family dies out is simply $\pi_0$, it follows that
            \begin{equation*}
                \PP\left( \text{population dies out}|X_1=j \right) = \pi_0^j,
            \end{equation*}
            which means
            \begin{equation}
                \pi_0 = \sum^{\infty}_{j=0}\pi_0^j\alpha_j.
            \end{equation}
            Clearly $\pi_0=0$ is not a solution and $\pi_0=1$ is a solution to [3.14]. 

            Now, it can be shown that, by defining $\alpha:\left[ 0,1 \right]\to\R$ by
            \begin{equation*}
                \alpha\left( z \right) = \sum^{\infty}_{j=0}z^j\alpha_j,
            \end{equation*}
            then $\alpha$ admits another root in $\left( 0,1 \right)$ besides $1$, say $z_0$, when $\mu>1$ (when $\mu=1$, $1$ is the unique root of $\alpha$). Therefore, we have to determine if $\pi_0=z_0$ or $\pi_0=1$ when $\mu>1$.

            To determine this, let $z^{*}\in\left\lbrace z_0,1 \right\rbrace$. Then by induction, we can show that
            \begin{equation*}
                z^{*}\geq\PP\left( X_n=0 \right)
            \end{equation*}
            for all $n\in\N\cup\left\lbrace 0 \right\rbrace$. As a result, it follows that
            \begin{equation*}
                z^{*} = \lim_{n\to\infty}z^{*}\geq \lim_{n\to\infty}\PP\left( X_n=0 \right) = \pi_0.
            \end{equation*}
            Thus $\pi_0$ is equal to the smallest element of $\left\lbrace z_0,1 \right\rbrace$, namely $z_0$.

            It is only when $\mu>1$ (referred to as \textit{supercritical case}), $\pi_0\in\left( 0,1 \right)$.
    \end{itemize} 

    \ex Given the following offspring probabilities, what is the probability that the population dies out in the long run assuming that $X_0=1$?

    \begin{enumerate}
        \item $\alpha_0=\frac{3}{4},\alpha_1=\frac{1}{8},\alpha_2=\frac{1}{8}$.
           
            \begin{subproof}[Answer]
                First, we calculate
                \begin{equation*}
                    \mu = 0\cdot \frac{3}{4} + 1\cdot \frac{1}{8} + 2\cdot \frac{1}{8} = \frac{3}{8}.
                \end{equation*}
                Since $\mu<1$, we are in a critical case, so $\pi_0=1$. Thus the population will die out almost surely.
            \end{subproof}

        \item 

            \begin{subproof}[Answer]
                Note that
                \begin{equation*}
                    \mu = 0\cdot \frac{1}{5} + 1\cdot \frac{1}{10} + 2\cdot \frac{7}{10} = \frac{3}{2}.
                \end{equation*}
                Since $\mu>1$, we are in a supercritical ccase, so $\pi_0\in\left( 0,1 \right)$. To find $\pi_0$, we solve [3.14]:
                \begin{equation}
                    z = \sum^{\infty}_{j=0} z^j\alpha_j = \frac{1}{5} + \frac{1}{10}z + \frac{7}{10}z^{2}.
                \end{equation}
                Rearranging [3.15] gives
                \begin{equation*}
                    7z^{2}-9z+2=0,
                \end{equation*}
                whose smallest root is
                \begin{equation*}
                    \frac{9-\sqrt{81-56}}{14} = \frac{4}{14} = \frac{2}{7}.
                \end{equation*}
                Thus $\pi_0 = \frac{2}{7}$.
            \end{subproof}
    \end{enumerate}

    \np We have some remarks.
    \begin{enumerate}
        \item In the case when $X_0=n$ almost surely for some $n\in\N$, the population will die out if and only if the families of each of the $n$ members of the initial generation die out. As a result, it immediately follows out that the \textit{extinction probability} is simply $\pi_0^n$.

        \item For certain choices of the offspring distriubtion, the Galton-Watson branching process is not very interesting to analyze. For example, with $X_0=1, a_r=1$ for some $r\in\N\cup\left\lbrace 0 \right\rbrace$, the evolution of the process is almost surely deterministic:
            \begin{equation*}
                \PP\left( X_n=r^n \right) = 1
            \end{equation*}
            for all $n\in\N\cup\left\lbrace 0 \right\rbrace$. Another uninteresting case occurs when $\alpha_0,\alpha_1>0$ and $\alpha_0+\alpha_1=1$. In this situation, the polulation remains at its initial size $X_0=1$ for a random number of generations (according to a geometric distribution), before dying out completely.
    \end{enumerate}

    \section{Gambler's Ruin}

    \np One of the most powerful ideas in the theory of DTMCs is that many fundamental probabilities and expectations can be computed as the solutions of systems of linear equations. We have already seen one such example of this through the application of the BLT. In what follows, we will continue to illustrate this idea by deriving appropirate linear systems for a number of key probabilities and expectations that arise in certain settings.

    \ex[Gambler's Ruin Problem]Consider a gambler who, at each play of a game, has probability $p\in\left( 0,1 \right)$ of winning one unit and probability $q=1-p$ of losing one unit. Assume that successive plays of the game are independent. If the gambler initially begins with $i$ units, what is the probability that the gambler's fortune will reach $N\in\N$ units before reaching $0$ units?

    \begin{subproof}[Answer]
        For each $n\in\N\cup\left\lbrace 0 \right\rbrace$, define $X_n$ as the gambler's fortune after the $n$th play of the game, with $X_0=i$ for some $i\in\N$. Clearly, $\left( X_{n} \right)^{}_{n\in\N\cup\left\lbrace 0 \right\rbrace}$ is a stationary DTMC with TPM
        \begin{equation*}
            P = 
            \begin{bmatrix}
                1 &  &  &  &  \\
                q & 0 & p &  &  \\
                 & \ddots & \ddots & \ddots &  \\
                 &  & q & 0 & p \\
                 &  &  &  & 1 \\
            \end{bmatrix}.
        \end{equation*}
        Note that states $0,N$ are absorving, so recurrent. States $1,\ldots,N-1$ are in the same communication class, and it is straightforward to show that they are transient. The goal is to determine
        \begin{equation*}
            G_i = \PP\left( \text{the gambler's fortune will eventually reach $N$}|X_0=i \right)
        \end{equation*}
        for all $i\in\left\lbrace 0,\ldots,N \right\rbrace$. This means
        \begin{equation*}
            \lim_{n\to\infty} P^{\left( n \right)} = 
            \begin{bmatrix}
                1 & 0 & \cdots & 0 & 0 \\
                1-G_1 & 0 & \cdots & 0 & G_1 \\
                \vdots & \vdots & \ddots & \vdots & \vdots \\
                1-G_{N-1} & 0 & \cdots & 0 & G_{N-1} \\
                0 & 0 & \vdots & 0 & 1 \\
            \end{bmatrix}.
        \end{equation*}
        From above, note that $G_0=0, G_N=1$. Moreover, by conditioning on the outcome of the very first game, we readily obtain for all $i\in\left\lbrace 1,\ldots,N-1 \right\rbrace$ that
        \begin{equation*}
            G_i = pG_{i+1}+qG_{i-1}.
        \end{equation*}
        But by definition, $p+q=1$, so
        \begin{equation*}
            pG_i+qG_i = pG_{i+1}+qG_{i-1},
        \end{equation*}
        rearranging which gives
        \begin{equation*}
            G_{i+1}-G_i = \frac{q}{p}\left( G_i-G_{i-1} \right).
        \end{equation*}
        But note that
        \begin{flalign*}
            && G_2-G_1 & = \frac{q}{p}\left( G_1-G_0 \right) = \frac{q}{p}G_1 && \\
            && G_3-G_2 & = \frac{q}{p}\left( G_2-G_1 \right) = \left( \frac{q}{p} \right)^{2}G_1 && \\
            && G_4-G_3 & = \frac{q}{p}\left( G_3-G_2 \right) = \left( \frac{q}{p} \right)^{3}G_1 \\
            && & \vdots && \\
            && G_{i+1}-G_i & = \frac{q}{p}\left( G_i-G_{i-1} \right) = \left( \frac{q}{p} \right)^{i}G_1
        \end{flalign*}
        by induction. Note that the above $i$ equations are linear, in terms of $G_1,\ldots,G_{i+1}$. Moreover, summing these $i$ equations results in
        \begin{equation*}
            G_{i+1}-G_1 = G_1 \sum^{i}_{j=1} \left( \frac{q}{p} \right)^j 
        \end{equation*}
        so
        \begin{equation*}
            G_{i+1} = G_1 \sum^{i}_{j=0} \left( \frac{q}{p} \right)^j .
        \end{equation*}
        Equivalently,
        \begin{equation*}
            G_i = 
            \begin{cases} 
                G_1 \frac{1-\left( \frac{q}{p} \right)^{i-1}}{1-\frac{q}{p}} & \text{if $p\neq \frac{1}{2}$}\\
                iG_1 & \text{if $p=\frac{1}{2}$}
            \end{cases}
        \end{equation*}
        by geometric series. In particular, when $i=N$, we obtain
        \begin{equation*}
            1 = G_N = \frac{1-\left( \frac{q}{p} \right)^N}{1-\left( \frac{q}{p} \right)} G_1
        \end{equation*}
        for $p\neq \frac{1}{2}$, which means
        \begin{equation*}
            G_1 = \frac{1-\left( \frac{q}{p} \right)}{1-\left( \frac{q}{p} \right)^N}.
        \end{equation*}
        Similarly, for $p=\frac{1}{2}$, we find
        \begin{equation*}
            G_1 = \frac{1}{N}.
        \end{equation*}
        Combining both cases, we obtain
        \begin{equation*}
            G_i = 
            \begin{cases} 
                \frac{1-\left( \frac{q}{p} \right)^i}{1-\left( \frac{q}{p} \right)^N} & \text{if $p\neq \frac{1}{2}$} \\
                \frac{i}{N} & \text{if $p=\frac{1}{2}$}
            \end{cases}
        \end{equation*}
        for all $i\in\left\lbrace 0,\ldots,N \right\rbrace$ (the formula we derived for $1,\ldots,N-1$ works for $0,N$ as well).
    \end{subproof}

    \np We have some remarks.
    \begin{enumerate}
        \item An interesting question to ask is \textit{what happens to the gambler's probability of winning the jackpot, given an initial fortune of $i$ units, as $N$ grows larger (i.e. $N\to\infty$)?} In other words, we are interested in what happens to the limit of $G_i$ as $N\to\infty$. Lookingg at three cases based on the value of $p$, we see
            \begin{itemize}
                \item \textit{when $p=\frac{1}{2}$,} $G_i=\frac{1}{N}\to 0$ as $N\to\infty$;
                \item \textit{when $p<\frac{1}{2}$,} $G_i = \frac{1-\left( \frac{q}{p} \right)^i}{1-\left( \frac{q}{p} \right)^N}\to 0$ as $N\to\infty$; and
                \item \textit{when $p>\frac{1}{2}$,} $G_i = \frac{1-\left( \frac{q}{p} \right)^i}{1-\left( \frac{q}{p} \right)^N}\to 1-\left( \frac{q}{p} \right)^i$ as $N\to\infty$.
            \end{itemize} 
        Simply put, only when $p>\frac{1}{2}$ does a positive probability exist that the gambler's fortune will increase indefinitely. Otherwise, the gambler is sure to go broke.

        \item In our study of the \textit{random walk} in (EX 3.26) featuringg a DTMC on the state space $\Z$ with transition probabilities analogous to those in the gambler's ruin problem, we previously showed that
            \begin{equation*}
                f_{0,0} = \left( 1-p \right)f_{-1,0} + pf_{1,0}.
            \end{equation*}
            Suppose that $p>\frac{1}{2}$. First of all, note that
            \begin{flalign*}
                && f_{1,0} & = \PP\left( \text{random walk ever makes a future visit to state 0 starting from state 1} \right) && \\ 
                && & = \lim_{N\to\infty}\PP\left( \text{gambler's ruin ends up in bankruptcy}|X_0=1 \right) && \\
                && & = 1-\left( 1-\left( \frac{1-p}{p} \right)^1 \right) = \frac{1-p}{p}.
            \end{flalign*}
    \end{enumerate}



















    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

\end{document}
